{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sampleSubmission.csv', 'test1', 'train']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by \n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import csv\n",
    "import glob\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import shuffle\n",
    "import glob\n",
    "#from torchsummary import summary\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"c:/Users/Asus/Desktop/HW/dogs-vs-cats/input\"))\n",
    "%matplotlib inline\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(50, 100, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=14400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 50, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(50, 100, 7)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(100 * 12 * 12, 120)\n",
    "        self.fc2 = nn.Linear(120, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 100 * 12 * 12)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0])\n"
     ]
    }
   ],
   "source": [
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "cat_dog_train_path = 'c:/Users/Asus/Desktop/HW/dogs-vs-cats/input/train/*.jpg'\n",
    "    # read addresses and labels from the 'train' folder\n",
    "addrs = glob.glob(cat_dog_train_path)\n",
    "labels = [ [1,0] if 'cat' in addr else [0,1] for addr in addrs]  # 1 = Cat, 0 = Dog\n",
    "    # to shuffle data\n",
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)\n",
    "    print(labels[0:10])\n",
    "        \n",
    "    # Divide the hata into 60% train, 20% validation, and 20% test\n",
    "train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "train_labels = labels[0:int(0.6*len(labels))]\n",
    "    #train_addrs.size\n",
    "    \n",
    "val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "    \n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " #loop over train addresses\n",
    "train_data = []\n",
    "for i in range(len(train_addrs[:1000])):\n",
    "    # print how many images are saved every 10 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "    # read an image and resize to (64, 64)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = train_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    train_data.append([np.array(img), np.array(train_labels[i])])\n",
    "shuffle(train_data)\n",
    "np.save('train_data.npy', train_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# loop over test addresses\n",
    "#creating test data\n",
    "test_data = []\n",
    "for i in range(len(test_addrs[:1000])):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "    # read an image and resize to (64, 64)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    test_data.append([np.array(img), np.array(labels[i])])\n",
    "shuffle(test_data)\n",
    "np.save('test_data.npy', test_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "# loop over val addresses\n",
    "val_data = []\n",
    "for i in range(len(val_addrs[:1000])):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Val data: {}/{}'.format(i, len(val_addrs)))\n",
    "    # read an image and resize to (64, 64)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = val_addrs[i]\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    val_data.append([np.array(img), np.array(labels[i])])\n",
    "shuffle(val_data)\n",
    "np.save('val_data.npy', val_data)\n",
    "    #print(val_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 64, 64])\n",
      "torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "X = np.array([i[0] for i in train_data]).reshape(-1,64,64,3)\n",
    "X = Variable(torch.Tensor(X))\n",
    "X = X.reshape(-1,64,64,3)\n",
    "X = X.permute(0,3,1,2)\n",
    "print(X.shape)\n",
    "#Y = Variable(torch.Tensor(Y))\n",
    "\n",
    "Y = np.array([i[1] for i in train_data])\n",
    "target = Variable(torch.Tensor(Y))\n",
    "target = target.type(torch.LongTensor)\n",
    "\n",
    "print(target.shape)\n",
    "#print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.7742999196052551\n",
      "1 : 0.5221154689788818\n",
      "2 : 0.328360915184021\n",
      "3 : 0.31435468792915344\n",
      "4 : 0.31341829895973206\n",
      "5 : 0.31330010294914246\n",
      "6 : 0.3132755756378174\n",
      "7 : 0.3132682740688324\n",
      "8 : 0.3132655620574951\n",
      "9 : 0.31326431035995483\n",
      "10 : 0.31326374411582947\n",
      "11 : 0.3132633566856384\n",
      "12 : 0.3132632076740265\n",
      "13 : 0.31326305866241455\n",
      "14 : 0.31326302886009216\n",
      "15 : 0.3132629692554474\n",
      "16 : 0.3132629096508026\n",
      "17 : 0.3132629096508026\n",
      "18 : 0.3132628798484802\n",
      "19 : 0.3132628798484802\n",
      "20 : 0.31326285004615784\n",
      "21 : 0.31326285004615784\n",
      "22 : 0.31326285004615784\n",
      "23 : 0.31326285004615784\n",
      "24 : 0.31326282024383545\n",
      "25 : 0.31326282024383545\n",
      "26 : 0.31326282024383545\n",
      "27 : 0.31326282024383545\n",
      "28 : 0.31326282024383545\n",
      "29 : 0.31326282024383545\n",
      "30 : 0.31326282024383545\n",
      "31 : 0.31326282024383545\n",
      "32 : 0.31326282024383545\n",
      "33 : 0.31326282024383545\n",
      "34 : 0.31326282024383545\n",
      "35 : 0.31326282024383545\n",
      "36 : 0.31326282024383545\n",
      "37 : 0.31326282024383545\n",
      "38 : 0.31326282024383545\n",
      "39 : 0.31326282024383545\n",
      "40 : 0.31326282024383545\n",
      "41 : 0.31326282024383545\n",
      "42 : 0.31326282024383545\n",
      "43 : 0.31326282024383545\n",
      "44 : 0.31326282024383545\n",
      "45 : 0.31326282024383545\n",
      "46 : 0.31326282024383545\n",
      "47 : 0.31326282024383545\n",
      "48 : 0.31326282024383545\n",
      "49 : 0.31326282024383545\n",
      "50 : 0.31326282024383545\n",
      "51 : 0.31326282024383545\n",
      "52 : 0.31326282024383545\n",
      "53 : 0.31326282024383545\n",
      "54 : 0.31326282024383545\n",
      "55 : 0.31326282024383545\n",
      "56 : 0.31326282024383545\n",
      "57 : 0.31326282024383545\n",
      "58 : 0.31326282024383545\n",
      "59 : 0.31326282024383545\n",
      "60 : 0.31326282024383545\n",
      "61 : 0.31326282024383545\n",
      "62 : 0.31326282024383545\n",
      "63 : 0.31326282024383545\n",
      "64 : 0.31326282024383545\n",
      "65 : 0.31326282024383545\n",
      "66 : 0.31326282024383545\n",
      "67 : 0.31326282024383545\n",
      "68 : 0.31326282024383545\n",
      "69 : 0.31326282024383545\n",
      "70 : 0.31326282024383545\n",
      "71 : 0.31326282024383545\n",
      "72 : 0.31326282024383545\n",
      "73 : 0.31326282024383545\n",
      "74 : 0.31326282024383545\n",
      "75 : 0.31326282024383545\n",
      "76 : 0.31326282024383545\n",
      "77 : 0.31326282024383545\n",
      "78 : 0.31326282024383545\n",
      "79 : 0.31326282024383545\n",
      "80 : 0.31326282024383545\n",
      "81 : 0.31326282024383545\n",
      "82 : 0.31326282024383545\n",
      "83 : 0.31326282024383545\n",
      "84 : 0.31326282024383545\n",
      "85 : 0.31326282024383545\n",
      "86 : 0.31326282024383545\n",
      "87 : 0.31326282024383545\n",
      "88 : 0.31326282024383545\n",
      "89 : 0.31326282024383545\n",
      "90 : 0.31326282024383545\n",
      "91 : 0.31326282024383545\n",
      "92 : 0.31326282024383545\n",
      "93 : 0.31326282024383545\n",
      "94 : 0.31326282024383545\n",
      "95 : 0.31326282024383545\n",
      "96 : 0.31326282024383545\n",
      "97 : 0.31326282024383545\n",
      "98 : 0.31326282024383545\n",
      "99 : 0.31326282024383545\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss  = 0.0\n",
    "    optimizer.zero_grad() #zero the parameter gradients\n",
    "    output = net(X)\n",
    "    \n",
    "    loss = criterian(output, torch.max(target, 1)[1])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    print(epoch, ':', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 64, 64])\n",
      "torch.Size([1000, 2])\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        ...,\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "test = np.array([i[0] for i in test_data]).reshape(-1,64,64,3)\n",
    "test = Variable(torch.Tensor(test))\n",
    "test = test.reshape(-1,64,64,3)\n",
    "test = test.permute(0,3,1,2)\n",
    "print(test.shape)\n",
    "#Y = Variable(torch.Tensor(Y))\n",
    "\n",
    "tlabels = np.array([i[1] for i in test_data])\n",
    "tlabels = Variable(torch.Tensor(tlabels))\n",
    "tlabels = tlabels.type(torch.long)\n",
    "\n",
    "print(tlabels.shape)\n",
    "print(tlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy of the network on the1000train images: 100.000000 %\n",
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(X,target):\n",
    "        images, labels = data\n",
    "        images = images.reshape(1,3,64,64)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        #total += labels.size(0)\n",
    "        if((predicted == 0 and labels[0] == 1) or (predicted == 1 and labels[1]==1) ):\n",
    "            correct+=1\n",
    "        #correct += (predicted == labels).sum().item()\n",
    "        #print(outputs,labels)\n",
    "total = X.shape[0]\n",
    "print('Train accuracy of the network on the' + str(total) +  'train images: %f %%' % (\n",
    "    100 * (correct*1.0) / total) )\n",
    "print(correct, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the network on the 1000 test images: 100.000000 %\n",
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in zip(test,tlabels):\n",
    "        images, labels = data\n",
    "        images = images.reshape(1,3,64,64)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        #total += labels.size(0)\n",
    "        if((predicted == 0 and labels[0] == 1) or (predicted == 1 and labels[1]==1) ):\n",
    "            correct += 1\n",
    "            \n",
    "total = test.shape[0]\n",
    "print('Test accuracy of the network on the ' + str(total) +  ' test images: %f %%' % (\n",
    "    100 * (correct*1.0) / total) )\n",
    "print(correct, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
